{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Temperature Downscaling of Amsterdam City using LightGBM Model**\n",
        "\n",
        "**Author:** [Fatemeh Chajaei](https://github.com/FatemehCh97)"
      ],
      "metadata": {
        "id": "t-jiNB2lrN3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Packages"
      ],
      "metadata": {
        "id": "7ONt27f5rZGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from hyperopt.pyll import scope\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "VNPXGAUrrISq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "from scipy.stats import skew"
      ],
      "metadata": {
        "id": "TMPVY90Jv3q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "xeTSWM7suqyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "param_path = r\"D:\\Code\\Amsterdam Parameter\\Train_Test\"\n",
        "\n",
        "# df_train_avg = pd.read_csv(os.path.join(param_path, \"Parameters_DataFrame.csv\"))\n",
        "# df_test_avg = pd.read_csv(os.path.join(param_path, \"Test_Parameters_DataFrame.csv\"))\n",
        "\n",
        "# df_train_max = pd.read_csv(os.path.join(param_path, \"Parameters_DataFrame_max.csv\"))\n",
        "# df_test_max = pd.read_csv(os.path.join(param_path, \"Test_Parameters_DataFrame_max.csv\"))\n",
        "\n",
        "# df_train_min = pd.read_csv(os.path.join(param_path, \"Parameters_DataFrame_min.csv\"))\n",
        "# df_test_min = pd.read_csv(os.path.join(param_path, \"Test_Parameters_DataFrame_min.csv\"))\n",
        "\n",
        "\"\"\"Train/Test Avg\"\"\"\n",
        "df = pd.read_csv(os.path.join(param_path, \"Train_Parameters_DataFrame.csv\"))\n",
        "df_test = pd.read_csv(os.path.join(param_path, \"Test_Parameters_DataFrame.csv\"))"
      ],
      "metadata": {
        "id": "0ADieTGMrisQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we do this for each selected days (January 17, 18, and 19, May 4, 5, and 6, July 18, 19, and 20, and October 24, 25, and 26, 2017)"
      ],
      "metadata": {
        "id": "QmnqRGWytrGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amst_param_path = r\"D:\\Code\\Temp_Prediction_Amsterdam\\Param\\Parameters_DataFrame_AVG_May_04.csv\"\n",
        "amst_df = pd.read_csv(amst_param_path)"
      ],
      "metadata": {
        "id": "16ytMRqatUkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[df.columns[1:15]]\n",
        "X_test = df_test[df_test.columns[1:15]]\n",
        "X_amst = amst_df[amst_df.columns[1:15]]\n",
        "\n",
        "\n",
        "df_all = np.concatenate((X, X_test, X_amst))"
      ],
      "metadata": {
        "id": "4bdxt8MDuNYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "Xs = scaler.fit_transform(df_all)\n",
        "\n",
        "\n",
        "y = df.loc[:,['Temp']]\n",
        "y = y.to_numpy()\n",
        "y = np.ravel(y)\n",
        "Xtrain = Xs[0:75268]\n",
        "\n",
        "\n",
        "y_test = df_test.loc[:,['Temp']]\n",
        "y_test = y_test.to_numpy()\n",
        "y_test = np.ravel(y_test)\n",
        "Xtest = Xs[75268:2374848]\n",
        "\n",
        "\n",
        "Xamst = Xs[2374848:]"
      ],
      "metadata": {
        "id": "7KjWnhdfuQRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HyperParameter Tuning"
      ],
      "metadata": {
        "id": "rSXMY004ujgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "param_hyperopt= {\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1)),\n",
        "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 2500, 50)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 50, 1)),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 1, 50, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.01, 1.0),\n",
        "    'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart']),\n",
        "    'subsample': hp.uniform('subsample', 0.01, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.01, 1.0),\n",
        "    # 'reg_lambda': hp.uniform('log-uniform', 1e-9, 1),      # L2 regularization\n",
        "    # 'reg_alpha': hp.uniform('log-uniform', 1e-9, 1),       # L1 regularization\n",
        "    }"
      ],
      "metadata": {
        "id": "Hx11bLy1ua5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperopt(param_space, X_train, y_train, num_eval):\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    def objective_function(params):\n",
        "        reg = LGBMRegressor(**params)\n",
        "        score = cross_val_score(reg, Xtrain, y, cv=5).mean()\n",
        "        return {'loss': -score, 'status': STATUS_OK}\n",
        "\n",
        "    trials = Trials()\n",
        "    best_param = fmin(objective_function,\n",
        "                      param_space,\n",
        "                      algo=tpe.suggest,\n",
        "                      max_evals=num_eval,\n",
        "                      trials=trials,\n",
        "                      rstate= np.random.default_rng(1))\n",
        "    loss = [x['result']['loss'] for x in trials.trials]\n",
        "\n",
        "    #best_param_values = [x for x in best_param.values()]\n",
        "\n",
        "    if best_param['boosting_type'] == 0:\n",
        "        boosting_type = 'gbdt'\n",
        "    else:\n",
        "        boosting_type= 'dart'\n",
        "\n",
        "\n",
        "\n",
        "    reg_best = LGBMRegressor(learning_rate=best_param['learning_rate'],\n",
        "                                  max_depth=int(best_param['max_depth']),\n",
        "                                  n_estimators=int(best_param['n_estimators']),\n",
        "                                  num_leaves=int(best_param['num_leaves']),\n",
        "                                  boosting_type=boosting_type,\n",
        "                                  colsample_bytree=best_param['colsample_bytree'],\n",
        "                                  subsample=best_param['subsample'],\n",
        "                                  reg_lambda=best_param['reg_lambda'])\n",
        "    reg_best.fit(Xtrain, y)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"##### Results\")\n",
        "    print(\"Score best parameters: \", min(loss)*-1)\n",
        "    print(\"Best parameters: \", best_param)\n",
        "    print(\"Time elapsed: \", time.time() - start)\n",
        "    print(\"Parameter combinations evaluated: \", num_eval)\n",
        "\n",
        "    return trials, reg_best"
      ],
      "metadata": {
        "id": "1goBoYZgudxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_hyperopt, reg_best = hyperopt(param_hyperopt, Xtrain, y, 20)"
      ],
      "metadata": {
        "id": "V3rX4X5iuhdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best HP"
      ],
      "metadata": {
        "id": "ZuTjU3kqu2b0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg_best = LGBMRegressor(learning_rate=0.045,\n",
        "                              max_depth=20,\n",
        "                              n_estimators=3000,\n",
        "                              num_leaves=28,\n",
        "                              boosting_type='gbdt',\n",
        "                              colsample_bytree=0.921596100038763,\n",
        "                              subsample=0.21744055366203258,\n",
        "                              reg_lambda=0.7329500731542772)"
      ],
      "metadata": {
        "id": "qXHcsQoAuzXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_best.fit(Xtrain, y)"
      ],
      "metadata": {
        "id": "HnJl_B0su6s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test[\"y_pred\"] = reg_best.predict(Xtest)\n",
        "df[\"y_pred\"] = reg_best.predict(Xtrain)"
      ],
      "metadata": {
        "id": "GCotJXqou8qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amst_df[\"Temp_Pred\"] = reg_best.predict(Xamst)"
      ],
      "metadata": {
        "id": "uQ4wDQYYvdz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_outputpath = r\"D:\\Code\\Temp_Prediction_Amsterdam\\Preds\\AVG\"\n",
        "\n",
        "amst_df_out = amst_df[['PointID', 'X', 'Y', 'Temp_Pred']].copy()\n",
        "amst_df_out.to_csv(os.path.join(outputpath, 'AvgTemp_Prediction_Jan_19.csv'),index=False)\n",
        "\n",
        "\n",
        "amst_df2.to_csv(os.path.join(outputpath, 'AvgTemp_Prediction_May_04_DataFrame.csv'),index=False)"
      ],
      "metadata": {
        "id": "jAwAhxoyvEzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "RWhe7cRcvksz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RMSE_train = np.round(mean_squared_error(df[\"Temp\"], df[\"y_pred\"], squared=False),3)\n",
        "MAE_train = np.round(mean_absolute_error(df[\"Temp\"], df[\"y_pred\"]),3)\n",
        "RMSE_test = np.round(mean_squared_error(df_test[\"Temp\"], df_test[\"y_pred\"], squared=False),3)\n",
        "MAE_test = np.round(mean_absolute_error(df_test[\"Temp\"], df_test[\"y_pred\"]),3)\n",
        "print (\"RMSE Train: \", RMSE_train, \"      RMSE Test: \", RMSE_test)\n",
        "print (\"MAE Train:  \", MAE_train, \"      MAE Test: \", MAE_test)"
      ],
      "metadata": {
        "id": "Oyj3gOVqvQDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAPE = mean_absolute_percentage_error(df_test[\"Temp\"], df_test[\"y_pred\"])\n",
        "print(\"MAPE: \", MAPE)"
      ],
      "metadata": {
        "id": "UXKRRfAgvtnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2 = r2_score(df_test[\"Temp\"], df_test[\"y_pred\"])\n",
        "print('r2 score for perfect model is', r2)"
      ],
      "metadata": {
        "id": "SvLkLR74vvT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error Disturbtion"
      ],
      "metadata": {
        "id": "C8Lz1WB8vzKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errors = df_test[\"Temp\"]-df_test[\"y_pred\"]\n",
        "\n",
        "mean = np.mean(errors)\n",
        "std_dev = np.std(errors)\n",
        "median = np.median(errors)\n",
        "skewness = skew(errors)\n",
        "\n",
        "\n",
        "# Plot the histogram\n",
        "plt.hist(errors, bins=30, edgecolor='black', alpha=0.5)\n",
        "\n",
        "# Add add additional statistics values as text to histogram\n",
        "plt.text(2.32,690000 , f'Mean: {mean:.3f}', ha='center', fontsize=12, fontname='Times New Roman')\n",
        "plt.text(2.35, 610000 , f'Median: {median:.3f}', ha='center', fontsize=12, fontname='Times New Roman')\n",
        "plt.text(2.385, 530000, f'Std Dev: {std_dev:.3f}', ha='center', fontsize=12, fontname='Times New Roman')\n",
        "plt.text(2.49, 440000, f'Skewness: {skewness:.3f}', ha='center', fontsize=12, fontname='Times New Roman')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Error', fontsize=14, fontname='Times New Roman')\n",
        "plt.ylabel('Frequency',labelpad=10, fontsize=14, fontname='Times New Roman')\n",
        "plt.title('Error Distribution Histogram', fontsize=14, fontname='Times New Roman')\n",
        "\n",
        "# Save plot\n",
        "plt.savefig(r'D:\\Code\\Temp_Prediction_Amsterdam\\Preds\\AVG\\Results\\Error_Distribution.png', bbox_inches='tight', dpi=300)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dAUUTtDfv127"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression Plot"
      ],
      "metadata": {
        "id": "8OG9RNofx3pT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.regplot(x='Temp', y='y_pred', data=df_test,  line_kws={'color': 'slategrey', 'linewidth': 0.9},\n",
        "            scatter_kws={'color': '#1eada5', 's': 5, 'facecolors': 'lightseagreen', 'linewidths': 0.5})\n",
        "\n",
        "# Set plot title and labels\n",
        "# plt.title('Regression Plot of Predicted vs Actual Temperature')\n",
        "plt.xlabel(\"UrbClim Temperature (K)\", labelpad=10, fontname='Times New Roman')\n",
        "plt.ylabel(\"Predicted Temperature (K)\", labelpad=10, fontname='Times New Roman')\n",
        "\n",
        "# Remove the top and right spines\n",
        "sns.despine(top=True, right=True)\n",
        "\n",
        "# Display evaluation metrics on the plot\n",
        "plt.text(295, 272, f'R2: {r2:.3f}', fontsize=12, ha='center', fontname='Times New Roman')\n",
        "plt.text(295.5, 277, f'MAE: {MAE_test:.3f}', fontsize=12, ha='center', fontname='Times New Roman')\n",
        "plt.text(295.8, 282, f'RMSE: {RMSE_test:.3f}', fontsize=12, ha='center', fontname='Times New Roman')\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig(r'D:\\Code\\Temp_Prediction_Amsterdam\\Preds\\AVG\\Results\\RegressionPlot_8.png', bbox_inches='tight', dpi=300)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iQQwvDO7x282"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Importance"
      ],
      "metadata": {
        "id": "BTrXY38-w42s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotImp(model, X , num = 20, fig_size = (40, 20)):\n",
        "    feature_imp = pd.DataFrame({'Value':(model.feature_importances_/sum(model.feature_importances_))*100,'Feature':X.columns})\n",
        "    plt.figure(figsize=fig_size)\n",
        "    sns.set(font_scale = 5)\n",
        "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",\n",
        "                                                        ascending=False)[0:num])\n",
        "\n",
        "\n",
        "    plt.title('LightGBM Features (avg over folds)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(r'D:\\Code\\Temp_Prediction_Amsterdam\\Preds\\AVG\\Results\\lgbm_FeatureImportances.png', bbox_inches='tight', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plotImp(reg_best, X_test)"
      ],
      "metadata": {
        "id": "WEWGFGwrw8ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation Plot"
      ],
      "metadata": {
        "id": "66hOXwd6xWnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(27, 16))\n",
        "\n",
        "# Plot the correlation between Independent Variable and Temperature as a scatter plot\n",
        "sns.scatterplot(data=amst_df, x='H', y='Temp_Pred', color='lightseagreen', edgecolor='lightseagreen', s=6, linewidths=1.5)\n",
        "\n",
        "# Set plot title and labels\n",
        "plt.title('Correlation Plot: Temperature vs. Area', fontname='Times New Roman')\n",
        "plt.xlabel('Area', fontname='Times New Roman')\n",
        "plt.ylabel('Temperature', fontname='Times New Roman')\n",
        "\n",
        "# Remove the top and right spines\n",
        "sns.despine(top=True, right=True)\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig(r'D:\\Code\\Temp_Prediction_Amsterdam\\Preds\\AVG\\Results\\CorrPlot_H_1.png', bbox_inches='tight', dpi=300)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NaayQIitxV-i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}