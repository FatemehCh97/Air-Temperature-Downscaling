{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jBF_CvB55dQF",
        "pgFVN7er5iam",
        "MGLIPIpdnRtV",
        "PHCW2Y-VcIi3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Author:** [Fatemeh Chajaei](https://github.com/FatemehCh97)"
      ],
      "metadata": {
        "id": "_1O97Yclxne4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBF_CvB55dQF"
      },
      "source": [
        "# Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_unet_collection\n",
        "from keras_unet_collection import losses\n",
        "import keras"
      ],
      "metadata": {
        "id": "m0W5DEPsrjPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqsL-QQYqO9P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tqdm import notebook, tnrange\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from osgeo import gdal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39FzQ3Ypb5UM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import array_to_img, img_to_array, load_img, save_img\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgFVN7er5iam"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0gx2u-XBxrm",
        "outputId": "3a9a4914-d8ee-47c4-caa3-2f35ed1a3601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJBvucVw3i7z"
      },
      "outputs": [],
      "source": [
        "# Amsterdam\n",
        "pred_dir = \"/content/drive/My Drive/Amsterdam Data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2SelJAlqO9b"
      },
      "outputs": [],
      "source": [
        "# Set some parameters\n",
        "im_width = 512\n",
        "im_height = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeU8cWcj4LVY"
      },
      "outputs": [],
      "source": [
        "pred_img_id = [] # list of names all images in the given path\n",
        "for f in glob.glob(os.path.join(pred_dir, \"*.tif\")):\n",
        "    pred_img_id.append(os.path.split(f)[1].split(\".\")[0])\n",
        "pred_img_id.sort()\n",
        "len(pred_img_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-TLvpk_50cu"
      },
      "outputs": [],
      "source": [
        "X_pred = np.zeros((len(pred_img_id), im_height, im_width, 1), dtype=np.float32)\n",
        "# X_pred = np.zeros((len(pred_img_id), im_height, im_width, 3), dtype=np.float32) # DeepLabV3+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nquR7WWG58rK"
      },
      "outputs": [],
      "source": [
        "for n, id_ in notebook.tqdm(enumerate(pred_img_id), total=len(pred_img_id)):\n",
        "    # Load images\n",
        "    pred_img = load_img(os.path.join(pred_dir, id_+\".tif\"), color_mode = \"grayscale\")\n",
        "    pred_x_img = img_to_array(pred_img)\n",
        "    # Normalization\n",
        "    X_pred[n] = (pred_x_img - pred_x_img.min()) / (pred_x_img.max() - pred_x_img.min())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(X_pred)"
      ],
      "metadata": {
        "id": "iZIhWSzaKGbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGLIPIpdnRtV"
      },
      "source": [
        "# Plot Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPx2q1l8nRtV"
      },
      "outputs": [],
      "source": [
        "# visualize samples and their predicted label\n",
        "def plot_sample(X, preds, binary_preds, ix=None):\n",
        "\n",
        "    if ix is None:\n",
        "        ix = random.randint(0, len(X))\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
        "    ax[0].imshow(X[ix, ..., 0], cmap='gray')\n",
        "    ax[0].set_title('DSM')\n",
        "\n",
        "\n",
        "    ax[1].imshow(binary_preds[ix].squeeze(), cmap='gray', vmin=0, vmax=1)\n",
        "    ax[1].set_title('Predicted Building Footprint')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHCW2Y-VcIi3"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iw7NnD233ynE"
      },
      "outputs": [],
      "source": [
        "with tf.device('/CPU:0'):\n",
        "    model = load_model(\"/content/drive/MyDrive/MegaImport/unet3p_pool_unpool.h5\", compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U74bjTQh2oUI"
      },
      "outputs": [],
      "source": [
        "# unet3+ loss/compile\n",
        "def hybrid_loss(y_true, y_pred):\n",
        "\n",
        "    loss_focal = losses.focal_tversky(y_true, y_pred, alpha=0.5, gamma=4/3)\n",
        "    loss_iou = losses.iou_seg(y_true, y_pred)\n",
        "\n",
        "    # (x)\n",
        "    #loss_ssim = losses.ms_ssim(y_true, y_pred, max_val=1.0, filter_size=4)\n",
        "\n",
        "    return loss_focal+loss_iou #+loss_ssim\n",
        "\n",
        "model.compile(loss=[hybrid_loss, hybrid_loss, hybrid_loss, hybrid_loss, hybrid_loss],\n",
        "                          loss_weights=[0.25, 0.25, 0.25, 0.25, 1.0],\n",
        "                          optimizer=keras.optimizers.Adam(learning_rate=1e-4))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.models.Model.summary(model)"
      ],
      "metadata": {
        "id": "uJPwfgB9bPXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPDU0aJ5cNeR"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(X_pred, batch_size=4, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drzN4VDj9hNi"
      },
      "outputs": [],
      "source": [
        "preds_unet3p = preds[-1]\n",
        "preds_tresh = (preds_unet3p > 0.5).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "polmPlFcVPu6"
      },
      "outputs": [],
      "source": [
        "plot_sample(X_pred, y_test, preds_unet3p, preds_tresh, ix=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgR7EdMGmcLa"
      },
      "source": [
        "## Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11tgwDVDy56g"
      },
      "outputs": [],
      "source": [
        "save_path = \"/content/unet3p_amst_pred\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmKFI4clfJdT"
      },
      "outputs": [],
      "source": [
        "gt = []\n",
        "for n, id_ in notebook.tqdm(enumerate(pred_img_id), total=len(pred_img_id)):\n",
        "    # Load images\n",
        "    pred_img_t = gdal.Open(pred_dir+\"/\"+id_+\".tif\")\n",
        "    gt.append(pred_img_t.GetGeoTransform())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rD-l2UJqh4kz"
      },
      "outputs": [],
      "source": [
        "for i, image in enumerate(preds_tresh, 0):\n",
        "    geotransform = (gt[i][0], gt[i][1], gt[i][2], gt[i][3], gt[i][4], gt[i][5])\n",
        "    img_raster = gdal.GetDriverByName('GTiff').Create(os.path.join(save_path, f'Pred_{i}.tif'), 512, 512, 1, gdal.GDT_Float32)\n",
        "    image_reshape = image.reshape(512, -1)\n",
        "    img_raster.GetRasterBand(1).WriteArray(image_reshape)\n",
        "    img_raster.SetGeoTransform(geotransform)\n",
        "    img_raster.SetProjection(pred_img_t.GetProjection())\n",
        "    img_raster.FlushCache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXMZNVZsWQ-R"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/unet3p_amst_pred.zip /content/unet3p_amst_pred"
      ]
    }
  ]
}